from fastapi import APIRouter, Form, File, UploadFile, HTTPException
from fastapi.responses import FileResponse
import os
import re
from dotenv import load_dotenv
from PIL import Image
from openai import OpenAI
import google.generativeai as genai
import requests
from io import BytesIO
from rembg import remove

# -----------------------------
# 1) í™˜ê²½ ì„¤ì •
# -----------------------------
load_dotenv(".env")

try:
    openai_client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
    genai.configure(api_key=os.environ["GEMINI_API_KEY"])
except KeyError as e:
    raise SystemExit(f"{e.args[0]}ë¥¼ .env íŒŒì¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# -----------------------------
# ìœ í‹¸: í”„ë¡¬í”„íŠ¸ ê¸¸ì´/ê³µë°± ì •ë¦¬
# -----------------------------
def _clamp_prompt(p: str, maxlen: int = 950) -> str:
    """
    DALLÂ·E í”„ë¡¬í”„íŠ¸ëŠ” 1000ì ì œí•œ â†’ ì•ˆì „í•˜ê²Œ 950ìë¡œ í´ë¨í”„.
    ì—°ì† ê³µë°±/ê°œí–‰ì„ í•œ ì¹¸ìœ¼ë¡œ ì •ë¦¬í•œ ë’¤ ìë¥¸ë‹¤.
    """
    p = re.sub(r"\s+", " ", (p or "")).strip()
    return p[:maxlen].rstrip()

# -----------------------------
# 2) ì´ë¯¸ì§€ ì•„ì›ƒí˜ì¸íŒ… í•¨ìˆ˜
# -----------------------------
def outpaint_image(input_path, user_prompt_kr, output_path, target_size=1024, target_ratio=1.0):
    temp_canvas_path = "temp_canvas_for_api.png"

    try:
        img = Image.open(input_path)
        img.save("debug_01_opened_image.png")
        print("âœ… ì›ë³¸ ì´ë¯¸ì§€ í™•ì¸ ì™„ë£Œ")
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{input_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ì´ë¯¸ì§€ë¥¼ ì—¬ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ - {e}")
        return

    # --- Gemini í”„ë¡¬í”„íŠ¸ ê°•í™” ---
    prompt_instruction = f"""
    You are a professional food photographer and a DALL-E prompt expert.
    Translate the Korean request into a vivid English prompt for an image outpainting task.
    Minimalist scene, ONLY the main food item, no other objects.

    Korean Request: "{user_prompt_kr}"
    """
    try:
        gemini_model = genai.GenerativeModel("gemini-1.5-flash-latest")
        response = gemini_model.generate_content(prompt_instruction)
        generated_prompt_en = (response.text or "").strip() or f"A minimalist food photo with: {user_prompt_kr}"
    except Exception as e:
        print(f"âš ï¸ Gemini ì˜¤ë¥˜: {e}")
        generated_prompt_en = f"A minimalist food photo with: {user_prompt_kr}"

    # â˜… í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ ì ìš© (1000ì â†“, ì•ˆì „í•˜ê²Œ 950ì)
    generated_prompt_en = _clamp_prompt(generated_prompt_en, 950)
    print(f"ğŸ“ Final prompt length: {len(generated_prompt_en)}")

    # --- ë°°ê²½ ì œê±° ---
    try:
        img_no_bg = remove(img)
        img_no_bg.save("debug_02_no_bg_image.png")
    except Exception as e:
        print(f"âš ï¸ ë°°ê²½ ì œê±° ì¤‘ ì˜¤ë¥˜: {e}")
        return

    # --- ìº”ë²„ìŠ¤ì— ë°°ì¹˜ ---
    canvas = Image.new("RGBA", (target_size, target_size), (0, 0, 0, 0))
    img_w, img_h = img_no_bg.size
    center_x, center_y = (target_size - img_w) // 2, (target_size - img_h) // 2
    canvas.paste(img_no_bg, (center_x, center_y), img_no_bg)

    # --- OpenAI DALL-E ì•„ì›ƒí˜ì¸íŒ… ---
    try:
        canvas.save(temp_canvas_path, "PNG")
        with open(temp_canvas_path, "rb") as image_file:
            response = openai_client.images.edit(
                model="dall-e-2",
                image=image_file,
                prompt=generated_prompt_en,
                size=f"{target_size}x{target_size}",
                n=1
            )
        image_url = response.data[0].url
        response_img = requests.get(image_url)
        gen_img = Image.open(BytesIO(response_img.content))
    except Exception as e:
        print(f"âš ï¸ OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return
    finally:
        if os.path.exists(temp_canvas_path):
            os.remove(temp_canvas_path)

    # --- ìµœì¢… í¬ë¡­ ---
    final_img = gen_img
    if abs(target_ratio - 1.0) > 1e-6:
        if target_ratio > 1:
            final_h = int(target_size / target_ratio)
            final_w = target_size
        else:
            final_w = int(target_size * target_ratio)
            final_h = target_size
        left = (target_size - final_w) // 2
        top = (target_size - final_h) // 2
        right = left + final_w
        bottom = top + final_h
        final_img = gen_img.crop((left, top, right, bottom))

    final_img.convert("RGB").save(output_path, "JPEG", quality=95)
    print(f"âœ… ìµœì¢… ì €ì¥ ì™„ë£Œ â†’ {output_path}")

# -----------------------------
# 3) FastAPI ë¼ìš°í„°
# -----------------------------
router = APIRouter()

@router.post("/v1/outpaint")
async def outpaint_endpoint(
    input_image: UploadFile = File(..., description="ì´ë¯¸ì§€ íŒŒì¼(PNG/JPG)"),
    user_prompt: str = Form(..., description="ë°°ê²½ ì»¨ì…‰ ì„¤ëª…(ìì—°ì–´, í•œêµ­ì–´ OK)"),
    ratio: str = Form("1:1", description="ì˜ˆ: 1:1, 4:5, 16:9"),
    size: int = Form(1024, description="ì§§ì€ ë³€ ê¸°ì¤€ í¬ê¸°")
):
    import tempfile
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as temp_in:
        temp_in.write(await input_image.read())
        input_path = temp_in.name

    try:
        w, h = map(int, ratio.split(":"))
        target_ratio = w / h
    except Exception:
        target_ratio = 1.0

    # ì¶œë ¥ íŒŒì¼ëª…: {ì„ì‹œíŒŒì¼ëª…}_food_AI.jpg
    output_path = input_path.replace(".jpg", "_food_AI.jpg")

    outpaint_image(input_path, user_prompt, output_path, target_size=size, target_ratio=target_ratio)

    return FileResponse(output_path, media_type="image/jpeg", filename=os.path.basename(output_path))